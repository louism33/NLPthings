
As information system resources can be large in size, and because of the business need for fast information retrieval, it is of great interest to Information Retrieval Systems to optimise both the speed of the retrieval, and the relevance of the data returned. It is important, therefore, to respond to a user‘s query by responding documents in such a way that we guarantee both high precision and high recall, without damaging the speed of the engine. A further business need is to avoid returning duplicate or near duplicate documents, as it is unlikely that one of these would be desirable, while the other is not.
Information Retrieval systems implement different methods of representing documents for fast search, as well as different ways of representing the user‘s queries.  This paper will consider the three archetypical models used for this purpose: From the set theoretical models, we shall consider the Boolean Model, from the algebraic models, the Vector Space model, and finally, from the Probabilistic Models, the Binary Independence Model. We shall present their advantages and disadvantages with reference to the above needs, and describe their effects on the ranking of results, where ranking is to be understood as returning results in decreasing order of relevance to the query, such that the first item returned is most likely to be the desired document.




In Boolean Information Retrieval (BIR), similarity relationships are determined by set operations. Documents shall be represented as a subset of the set of all index words (possibly stemmed words which characterise a document). Queries will take the form of boolean expressions. This can either be done implicitly (by allowing the user to specify keywords, which the engine will then join with either logical AND or logical OR operators), or explicitly, by allowing the user to write their own logical queries. Some engines may offer more options to the user, by including the NOT operator, which would require that a document not include the following expression, as well as parentheses, in order to enhance and clarify the meaning of their query. In principle, all boolean operators might see use, including XOR, NAND and others.
Retrieval is done by first translating the query into disjunctive or conjunctive normal form, then replacing each word in the query by the set of documents that include it, then solving the boolean expression for these sets. The final set of documents is the set which matches the user‘s query, and can be returned and displayed to the user. Enhancements to this basic model include allowing wildcard searching.

The first advantage of BIR is the simplicity of the model. By returning documents that exactly include the terms searched, users can easily refine their searches if the documents to not meet their information need (even if they do match the query). 
Furthermore, it is highly precise. The user gets exactly what they searched for. This can be ideal in more technical situations where users may have extremely clear requirements, and know what they want. Furthermore, if a user is aware of the fact that BIR is used, they can tailor their queries to make them precise, which is greatly suited to more technical environments, where the user may be searching for specific documents rather than general information. This is used to great effect in medical information searchers and legal information searchers.
A second advantage is the ease of implementation. Operations of sets are well supported in all major programming languages, and this makes the process of determining which documents to return very simple. As such, it can easily be added to a program whose main goal is not to do information retrieval. For example, it is common for BIR to be used in by email providers, to perform a simple keyword search of emails received, even though an email service‘s main goal is not to provide searching. It can also be used when searching through a hard-drive for example.
The BIR is also highly efficient. When a new document is added, one simply needs to scan it once, building the set of index terms, and then adding the document‘s unique identifier to a hashmap of index words to documents. Processing the user‘s query is then simply done by looking up the query terms in the hashmap (which can be done extremely quickly on modern hardware), then resolving the boolean expression.
Disadvantages
The BIR has some limitations which make needs to be addressed in a productive environment. 
First, in the version presented above, a document either has, or does not have, an index term in its description. While this gives a good idea of the content of the document, it misses a sense of quantity; we cannot know the extent to which a document talks about a certain topic. „We would like to accumulate evidence, giving more weight to documents that have a term several times as opposed to ones that contain it only once.“(Gao et al., 2004)
Further to this limitation, the BIR does not provide any term weights to the user‘s query either. This leads to treating all terms in the query as equally likely, which is unlikely to be ideal. Furthermore, the model does not treat the first words in the query as more relevant than later words in the query, even though it can usually be assumed that the first words will be more interesting to the writer of the query.
BIR assumes independence of terms in the query (and the documents), which causes a problem if one searches for a compound expression. Manning, Raghavan and Schütze give the example of „operating system“, a query which will not be interested in documents that include the words „operating“ and „system“, but not these two words together.
Third, we must consider how queries are interpreted. If we consider all query words to be joined with logical AND, we will tend to get results with high precision, but low recall, as only documents that include exactly all of the query will be returned. If we choose to use logical OR, we will tend to get low precision but high recall, as any document that includes at least on of the terms will be returned. Finding a middle ground with both high precision and recall is non trivial (Manning 2009). AND is too strict, OR is too lenient, and there is no clear way of deciding which to use.
In general, BIR is prone to over or under retrieval. If the query is short, and general, we may return large numbers of documents. If the query is highly specific, maybe nothing. Furthermore, any error in the query (such as an additional word or a typographical mistake) will dramatically change the results.
The BIR returns only documents that perfectly match the query, and has no principled way of returning partial matches. As such, it is difficult for a user, who does not have either experience with the model, or does not have a clear information need, to receive any documents that he will accept.
The BIR will also return large numbers of duplicate documents, as many documents have the same set-wise representation, and there is no way to distinguish between them. As explained above, a very similar document is highly unlikely to satisfy the user‘s need if the original document didn‘t.
Formulating complex queries, that may actually match the information desired, is not something most users do. One‘s ideal query may require a large number of parentheses and not operators, and therefore some grounding in boolean logic, which is a requirement we cannot put on most users. Writing good boolean logic is not easy, and a simple mistake in the use of brackets will completely change the resulting documents. Therefore, it is difficult to translate a user‘s need into a query.
The BIR as presented above, cannot learn. It will not improve as time goes on, even though it will process large amounts of data, which it could use to improve itself. Further down, we will see models that are able to solve this issue.
Effect on ranking
The basic version of BIR outlined above does not permit ranking results whatsoever. BIR queries return a set of matching documents, but do not give any indication of which may be more suitable to the user‘s query: a document is either suitable, or unsuitable. Of course, users will not think in this way, and will usually have preferences of one document over another. The BIR outlined above will not be able to represent this. In fact, if only one document returned is of interest to the user, finding this document will have O(n) complexity, with n being the number of documents returned, which can be very large indeed. If we could guarantee that only a small number of documents would be retrieved, so that the user may rapidly find the best result for the, this problem could be overcome, but we have seen previously that the BIR is prone to over-retrieval, thus making the task of finding the best result very challenging for the user. 
In order to rank results, we would require a mechanism for determining a document score which describes how good a match a document is for a query, but BIR does not provide this functionality. We will next consider a model that can more accurately rank the results of a query, while also managing the problem of over- or under- retrieval.


The main problem with Boolean model is its over, or under- retrieval (due to its inability to fetch partial matches) and the absence of any scoring procedure to rank the retrieved documents. We now analyse a model that attempts to remedy these problems.
The Vector Space Model (VSM) permits us to remedy some of the disadvantages of the BIR. Instead of representing documents as sets of index terms, they are instead represented as high-dimensional vectors, in which each entry in the vector corresponds to a term in the vocabulary, very often receiving its weight from a calculation of TF-IDF, or term frequency, inverse document frequency, which gives rarer terms a higher score (Büttcher, Clarke and Cormack 2010). Queries are represented the same way (in contrast to the BIR logical formulae). With the query vector in hand, we rank the documents in the collection by considering the cosine of the angle between the query vector and the document vector, by a simple application of the dot product . The larger the cosine (with 1 as the maximum value), the more similar the two vectors. This is because a cosine of 1 denotes an angle of 0 degrees, making the two vectors collinear, making the document a perfect fit for the query. A cosine of 0 means an angle of 90 degrees, which indicates that the query and document vectors are orthogonal, as different as it is possible to be. We now consider the strengths and weaknesses of this model.


The VSM solves many of the problems of the BIR. First, it allows us to solve the problem of over- and under-retrieval that faces the BIR. This is because the VSM effectively returns all documents in the collection, in decreasing order of likelihood. Even if not documents have a particularly high degree of similarity (for example, the highest cosine is 0.5), we may still return these as the most likely to fit the user‘s query. We do not easily find ourselves returning nothing, and can always rank results, even if they have a low degree of similarity. This may be the „middle ground“, where we can achieve both high precision and high recall. This allows for partial matching of a user‘s query, and can easily inform a ranking system.
A second advantage to VSM is that it requires no knowledge of the side of the user. In BIR we saw that many systems offer user‘s the ability to write precise queries, but require them to know boolean logical operators. VSMs do not require users to have any specific knowledge in order to use them, which is a clear advantage in a practical or business setting.
According to Büttcher, Clarke and Cormack, although the calculation of the cosine similarity may at first appear hugely expensive, queries tend to be short, and very manageable for modern computers, and while documents may have vectors with millions of non-zero entries, the length of this vector may be easily pre-computed, and stored alongside it, allowing for much faster retrieval. Therefore VSMs can count speed among their advantages.
A further advantage is due to the identical nature of the representation of a document and a query. This sameness allows us to use entire documents as queries, thus allowing us to return other documents that may be similar to the one queried. This has clear business applications, as one can then easily implement a „Similar pages“ or „Find more like this“ feature (Manning 2009).
Disadvantages
The VSM model is less intuitive than the BIR. The may lead to users being less clear on how their queries lead to the documents they are seeing. Furthermore, the cosine similarity only has empirical justification, it does not have a theoretical standing. We might ask why the cosine similarity represents relevance, and the answer can only be that it seems to, in practice.
As index terms are considered to be mutually independent, we see a similar downside to BIR with regard to compound expressions such as „operating system“ being unable to be represented. Furthermore, this model does not capture the semantics of the query or the document.
Although VSMs deal with many issues of BIR, one lacking feature is the NOT operator. In VSM queries, only positive terms can be included, and this leads to many results which include terms the user would like to exclude, but cannot. 
Although much of the cosine operation can be precomputed, it is still necessary to calculate the cosine similarity of the query and all documents, which has a higher time cost than BIR, thus making the VSM slower in practice ( P124) „a single similarity computation can entail a dot product in tens of thousands of dimensions, demanding tens of thousands of arithmetic operations„, in contrast to the small number of set-based operations of BIR (which is linear with the size of the query, and therefore rarely larger than 10).
A further issue that practical implementations of VSM need to contend with, is that VSMs will by default return very similar, or duplicate documents, which as previously outlined will not be suitable to the user.
The VSM shares one downside with the BIR, in that it cannot learn. It will always return the same results to a query, regardless of any available data that shows that the user does not consider these responses as suitable. 

In stark contrast to the BIR, VSMs give us a clear methodology for ranking documents returned. We simply order the documents by their cosine similarity, the higher the cosine, the higher the document‘s placement in the returned set. We no longer need to worry about over- or under-retrieval, as we effectively return all documents in the collection, and allow the user to navigate until they find what they are looking for. 


In the previous two models considered, matching a query to a set of documents was „ done in a formally defined but semantically imprecise calculus of index terms“ , meaning that in BIR and VSM, we have an „uncertain understanding of the information need“ from the query, and an „uncertain guess“ of whether a document is relevant to this query. In this section, we will analyse a Probabilistic Model (PM), which uses the mathematical tools of probability theory to reason under uncertainty in order to estimate „how likely it is that a document is relevant to an information need“ (Manning 2009, page 219).

As PM is is an abstract model, there are many implementations which can be used. We shall consider the Binary Independence Model (BIM), a practical model, which makes a number of assumptions to enable the abstract PM to work in practice. BIM represents documents as binary vectors (vectors whose elements are either 0 or 1), with a 1 indicating the presence of an index term., with queries being represented in a similar way. Of course, different documents may be represented by the same vector. A major assumption of this model is the assumption of term independence, meaning that terms in the document are considered to be independent of one another. This model further assumes that the relevance of each document is independent of the relevance of other documents. 
Ranking of the documents can be done in decreasing order of relevance (either directly by the probability, or, more commonly, by the odds that this document is relevant, calculated by dividing the probability that the document is relevant, given the document vector and the query vector, by the probability that it is not relevant, given the document vector and the query vector).
To calculate relevance, we may use term frequency, document frequency, document length, and other statistics that we can compute to estimate the probability of document relevance. (Manning 2009). The model then operates recursively, based on an initially guessed set of parameters.


PMs can be easily adapted to update their weights based on user input. This process is as following: 
Guess values for the probability of a term appearing in a document relevant to the query, and for the probability of a term appearing in a non relevant document.
Using these values, assemble a best guess of the set of relevant documents, which we present to the user.
Based on the user‘s actions (either consciously providing feedback, or by analysing their behaviour, such as clicks), update our values from 1.
      As such, PMs are the only model presented which can be said to improve as time goes on. In this way, it distinguishes itself from BIR and VSMs.
Unlike the Vector Space Model, whose justification is purely empirical, PMs have a firm theoretical foundation, as they directly rank by the probability a document may be relevant to the user.

Our model requires us to have values for the probability of a term appearing in a document relevant to the query, and for the probability of a term appearing in a non relevant document, but we do not have a perfect way of estimating these. As such, we must guess the initial values of the above probabilities.
This model requires more computational resources than previous models. This is due to the recursive nature of its operation, whose „complexity grows quickly [..] limiting the scalability of the engine based on the model“ (Lashkari et al, 2009). Even though the Naive Bayes assumption of conditional independence makes calculating the ranking is substantially faster than may be expected (Manning 2009), PMs are the slowest model we analyse in this text. This is one of the reasons that PMs have not, in the form presented above, seen widespread adoption.
The assumptions inherent in this model may cause problems:
According to Manning (2009), the assumption that terms are independent of each other, „is far from correct, but it nevertheless often gives satisfactory results in practice“. While the downsides of this assumption do not appear unmanageable, it damages the theoretical solidity of our model.
The assumption that the relevance of each document is independent of the relevance of other documents is more damaging. It is incorrect, as we end up returning many similar documents, even though only one would have sufficed, and leaves Manning to describe it as „especially harmful in practice“, due to its tendency to return near duplicate documents.
BIM, just like BIR, uses only binary weights, and so faces the same issue with not being able to represent magnitude in the documents (a document either has, or does not have, an index term associated to it, there are no shades of presence to mark the degree to which an index term is present).





Probability based models offer a clear method of ranking the documents returned. One simply returns documents based on their calculated probability of being relevant to the query, in decreasing order. Due to allowing user feedback, whether this is done by consciously ranking the results, or, more likely, by recording the placement in the ranking of the document the user eventually selects, this model is unique among the other two by not guaranteeing the same ranking every time. Both other models will always return the exact same documents, given the query and the set of all documents, but PMs may not do this. Therefore, user‘s will see the ranking subtly change over time, eventually becoming more accurate.



The most important conclusion to draw from this research is that there is no one best model of information retrieval. These models have trade-offs which must be well understood and carefully managed, thus allowing a model to be tailored to one‘s application. If designing a model for use by doctor to search for symptoms, a boolean model may be ideal, as this allows us to maximise its strengths (of clarity, precision and speed) while minimising its downsides (of query complexity and retrieval quantity). The same model would be unsuited for a general use engine, searching through billions of documents, as its downsides would outweigh its advantages. In practice, vector space models seem to outperform the other two when faced with large amounts of documents  (Baeza-Yates and Ribeiro-Neto, 1999).
The second most important conclusion we can draw, is that these models are not mutually exclusive. Some fit more easily together than others (the vector space model and probabilistic model both represent their documents as vectors for example, making a combination easier), but in principle, any archetype is compatible with any other. In practice, therefore, we would not expect to see any of the above models in their pure form. Some combinations that may be of benefit include:
Add the boolean NOT search operator to either of the other two presented models. This operator is hugely powerful, and difficult to replicate. It allows users with complex queries to get answers more easily, and allows users to easily refine their queries, if they receive documents they do not consider suitable.
On the topic of refinements, we can add the probabilistic model‘s ability to learn and improve to either of the other models. In BIR, this could be used to determine when to use AND or when to use OR, and in the VSM, could inform custom search weights, or inform the choice of vocabulary index. The addition of learning has another clear business advantage, in that it allows companies to distinguish themselves by knowing their user‘s better than their competition, thus virtually guaranteeing that a practical implementation of any of the three above models will include some form of learning.
The vector space model easily creates a hugely useful feature, in that it allows us to use documents as queries, thus returning similar pages to this one. Both other models might seek to implement this feature, as it has such clear applications and benefits to the users.

